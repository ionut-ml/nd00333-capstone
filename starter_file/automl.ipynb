{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1620122890366
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'ionut-automl-run'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: quick-starts-ws-143935\n",
            "Azure region: southcentralus\n",
            "Subscription id: 9a7511b8-150f-4a58-8528-3e7d50216c31\n",
            "Resource group: aml-quickstarts-143935\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1620122893749
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there is a compute cluster, if yes use it\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Choose a name for your CPU cluster\n",
        "cpu_cluster_name = \"ionut-compute\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
        "                                                           max_nodes=4)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1620122898216
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TabularDataset using TabularDatasetFactory\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "# Try to load the dataset from the Workspace. Otherwise, create it from the file\n",
        "\n",
        "found = False\n",
        "key = \"Heart Disease Dataset\"\n",
        "description_text = \"Heart Disease DataSet for Udacity Capstone Project (Source: UCI)\"\n",
        "\n",
        "if key in ws.datasets.keys(): \n",
        "        found = True\n",
        "        dataset = ws.datasets[key] \n",
        "\n",
        "if not found:\n",
        "        # Create AML Dataset and register it into Workspace\n",
        "        example_data = 'https://raw.githubusercontent.com/ionut-ml/nd00333-capstone/main/starter_file/heart.csv'\n",
        "        dataset = Dataset.Tabular.from_delimited_files(example_data)        \n",
        "        #Register Dataset in Workspace\n",
        "        dataset = dataset.register(workspace=ws,\n",
        "                                   name=key,\n",
        "                                   description=description_text)\n",
        "\n",
        "\n",
        "df = dataset.to_pandas_dataframe()\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "              age         sex          cp    trestbps        chol         fbs  \\\ncount  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \nmean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \nstd      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \nmin     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \nmax     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n\n          restecg     thalach       exang     oldpeak       slope          ca  \\\ncount  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \nmean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \nstd      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \nmin      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \nmax      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n\n             thal      target  \ncount  303.000000  303.000000  \nmean     2.313531    0.544554  \nstd      0.612277    0.498835  \nmin      0.000000    0.000000  \n25%      2.000000    0.000000  \n50%      2.000000    1.000000  \n75%      3.000000    1.000000  \nmax      3.000000    1.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>54.366337</td>\n      <td>0.683168</td>\n      <td>0.966997</td>\n      <td>131.623762</td>\n      <td>246.264026</td>\n      <td>0.148515</td>\n      <td>0.528053</td>\n      <td>149.646865</td>\n      <td>0.326733</td>\n      <td>1.039604</td>\n      <td>1.399340</td>\n      <td>0.729373</td>\n      <td>2.313531</td>\n      <td>0.544554</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.082101</td>\n      <td>0.466011</td>\n      <td>1.032052</td>\n      <td>17.538143</td>\n      <td>51.830751</td>\n      <td>0.356198</td>\n      <td>0.525860</td>\n      <td>22.905161</td>\n      <td>0.469794</td>\n      <td>1.161075</td>\n      <td>0.616226</td>\n      <td>1.022606</td>\n      <td>0.612277</td>\n      <td>0.498835</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>29.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>94.000000</td>\n      <td>126.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>71.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>47.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>120.000000</td>\n      <td>211.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>133.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>55.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>130.000000</td>\n      <td>240.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>153.000000</td>\n      <td>0.000000</td>\n      <td>0.800000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>61.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>140.000000</td>\n      <td>274.500000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>166.000000</td>\n      <td>1.000000</td>\n      <td>1.600000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>77.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>200.000000</td>\n      <td>564.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>202.000000</td>\n      <td>1.000000</td>\n      <td>6.200000</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1620122906968
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from train import clean_data\n",
        "\n",
        "# Use the clean_data function to clean your data.\n",
        "x, y = clean_data(dataset)\n",
        "\n",
        "# Split data into train and test sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Concat X_train & y_train into one df\n",
        "import pandas as pd\n",
        "df_train = pd.concat([x_train, y_train], axis=1)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1620122945851
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Save training data as csv\r\n",
        "\r\n",
        "if not os.path.isdir(\"train_data\"):\r\n",
        "    os.mkdir(\"train_data\")\r\n",
        "\r\n",
        "df_train.to_csv(\"./train_data/train_data.csv\",index=False)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620123107306
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload data as tabular dataset\r\n",
        "\r\n",
        "# get the datastore to upload prepared data\r\n",
        "datastore = ws.get_default_datastore()\r\n",
        "\r\n",
        "# upload the local file from src_dir to the target_path in datastore\r\n",
        "datastore.upload(src_dir='train_data', target_path='data')\r\n",
        "\r\n",
        "# create a dataset referencing the cloud location\r\n",
        "train_ds = Dataset.Tabular.from_delimited_files(path = [(datastore, ('data/train_data.csv'))])\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 1 files\n",
            "Uploading train_data/train_data.csv\n",
            "Uploaded train_data/train_data.csv, 1 files out of an estimated total of 1\n",
            "Uploaded 1 files\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620123110719
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\n",
        "    \"enable_early_stopping\" : True,\n",
        "    \"iteration_timeout_minutes\": 5,\n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"max_cores_per_iteration\": -1,\n",
        "#     \"primary_metric\" : 'AUC_weighted'\n",
        "}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(\n",
        "    compute_target=cpu_cluster_name,\n",
        "    experiment_timeout_minutes=30,\n",
        "    task=\"classification\",\n",
        "    primary_metric=\"accuracy\",\n",
        "    training_data=train_ds,\n",
        "    label_column_name='target',\n",
        "    n_cross_validations=5,\n",
        "    featurization= 'auto',\n",
        "    enable_onnx_compatible_models=True,\n",
        "    debug_log = \"automl_errors.log\",\n",
        "    **automl_settings\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1620123361156
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config, show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting remote run.\n",
            "No run_configuration provided, running on ionut-compute with default configuration\n",
            "Running on remote compute: ionut-compute\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>ionut-automl-run</td><td>AutoML_a5ab2c31-5a1f-4810-9cc8-e92c84bebaa2</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_a5ab2c31-5a1f-4810-9cc8-e92c84bebaa2?wsid=/subscriptions/9a7511b8-150f-4a58-8528-3e7d50216c31/resourcegroups/aml-quickstarts-143935/workspaces/quick-starts-ws-143935&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1598431107951
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(automl_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431121770
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best automl run\n",
        "best_automl_run, best_automl_onnx_model = automl_run.get_output(return_onnx_model=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431425670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model\n",
        "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
        "\n",
        "# Save model using Onnx Converter\n",
        "OnnxConverter.save_onnx_model(best_automl_onnx_model, file_path='./outputs/best_automl_onnx_model.onnx')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431426111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the hyperparameters for the best run\n",
        "best_automl_run, best_automl_onnx_model = automl_run.get_output()\n",
        "best_automl_run.get_tags()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}